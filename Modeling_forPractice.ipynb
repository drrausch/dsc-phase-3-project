{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import tree\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>count</th>\n",
       "      <th>popularity_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.598500</td>\n",
       "      <td>0.470100</td>\n",
       "      <td>267072.000000</td>\n",
       "      <td>0.376203</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.283050</td>\n",
       "      <td>-14.434300</td>\n",
       "      <td>0.209150</td>\n",
       "      <td>114.128800</td>\n",
       "      <td>0.358320</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.862538</td>\n",
       "      <td>0.441731</td>\n",
       "      <td>287280.000000</td>\n",
       "      <td>0.406808</td>\n",
       "      <td>0.081158</td>\n",
       "      <td>0.315215</td>\n",
       "      <td>-10.690000</td>\n",
       "      <td>0.176212</td>\n",
       "      <td>103.044154</td>\n",
       "      <td>0.268865</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.856571</td>\n",
       "      <td>0.348286</td>\n",
       "      <td>328920.000000</td>\n",
       "      <td>0.286571</td>\n",
       "      <td>0.024593</td>\n",
       "      <td>0.325786</td>\n",
       "      <td>-15.230714</td>\n",
       "      <td>0.118514</td>\n",
       "      <td>77.375857</td>\n",
       "      <td>0.354857</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.884926</td>\n",
       "      <td>0.425074</td>\n",
       "      <td>262890.962963</td>\n",
       "      <td>0.245770</td>\n",
       "      <td>0.073587</td>\n",
       "      <td>0.275481</td>\n",
       "      <td>-15.639370</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>88.667630</td>\n",
       "      <td>0.372030</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.510714</td>\n",
       "      <td>0.467143</td>\n",
       "      <td>270436.142857</td>\n",
       "      <td>0.488286</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>-10.236714</td>\n",
       "      <td>0.098543</td>\n",
       "      <td>122.835857</td>\n",
       "      <td>0.482286</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability    duration_ms    energy  instrumentalness  \\\n",
       "0      0.598500      0.470100  267072.000000  0.376203          0.010261   \n",
       "1      0.862538      0.441731  287280.000000  0.406808          0.081158   \n",
       "2      0.856571      0.348286  328920.000000  0.286571          0.024593   \n",
       "3      0.884926      0.425074  262890.962963  0.245770          0.073587   \n",
       "4      0.510714      0.467143  270436.142857  0.488286          0.009400   \n",
       "\n",
       "   liveness   loudness  speechiness       tempo   valence  key  mode  count  \\\n",
       "0  0.283050 -14.434300     0.209150  114.128800  0.358320    5     1     10   \n",
       "1  0.315215 -10.690000     0.176212  103.044154  0.268865    5     1     26   \n",
       "2  0.325786 -15.230714     0.118514   77.375857  0.354857    0     1      7   \n",
       "3  0.275481 -15.639370     0.123200   88.667630  0.372030    0     1     27   \n",
       "4  0.195000 -10.236714     0.098543  122.835857  0.482286    5     1      7   \n",
       "\n",
       "  popularity_labels  \n",
       "0        Successful  \n",
       "1        Successful  \n",
       "2        Successful  \n",
       "3        Successful  \n",
       "4        Successful  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all datasets\n",
    "\n",
    "data = pd.read_csv('Data/spotify_dataframe', index_col = 'Unnamed: 0')\n",
    "smote_data = pd.read_csv('Data/smote_data', index_col = 'Unnamed: 0')\n",
    "nm_data = pd.read_csv('Data/nearmiss_data', index_col = 'Unnamed: 0')\n",
    "\n",
    "data.drop(columns = ['artists', 'popularity', 'genres'], axis = 1, inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign variables\n",
    "X = data.drop('popularity_labels', axis = 1)\n",
    "X_smote = smote_data.drop('popularity_labels', axis = 1)\n",
    "X_nm = nm_data.drop('popularity_labels', axis = 1)\n",
    "\n",
    "y = data['popularity_labels']\n",
    "y_smote = smote_data['popularity_labels']\n",
    "y_nm = nm_data['popularity_labels']\n",
    "\n",
    "#train, test, split\n",
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size = .2, random_state = 42)\n",
    "X_train_smote, X_test_smote, y_train_smote,y_test_smote = train_test_split(X_smote, y_smote, test_size = .2, random_state = 42)\n",
    "X_train_nm, X_test_nm, y_train_nm, y_test_nm = train_test_split(X_nm, y_nm, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize data\n",
    "#ss = StandardScaler()\n",
    "\n",
    "#ss_train = ss.fit_transform(X_train)\n",
    "#ss_train_smote = ss.fit_transform(X_train_smote)\n",
    "#ss_train_nm = ss.fit_transform(X_train_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First vanilla models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 0.7619852489244008\n",
      "SMOTE: 0.7072391412880679\n",
      "NearMiss: 0.6145587287953618\n"
     ]
    }
   ],
   "source": [
    "#realized I could've made my life easier with a pipeline - so going to add that in here! Better late than never\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('ss', StandardScaler()),\n",
    "                 ('tree', DecisionTreeClassifier(random_state=10))])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.fit(X_train_smote, y_train_smote)\n",
    "pipe.fit(X_train_nm, y_train_nm)\n",
    "\n",
    "print('Decision Tree Performance')\n",
    "print('Original: {}'.format(pipe.score(X_test, y_test)))\n",
    "print('SMOTE: {}'.format(pipe.score(X_test_smote, y_test_smote)))\n",
    "print('NearMiss: {}'.format(pipe.score(X_test_nm, y_test_nm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 0.6324523663183774\n",
      "SMOTE: 0.6442336495257114\n",
      "NearMiss: 0.6055400472407129\n"
     ]
    }
   ],
   "source": [
    "pipe_KNN = Pipeline([('ss', StandardScaler()),\n",
    "                 ('knn', KNeighborsClassifier())])\n",
    "\n",
    "pipe_KNN.fit(X_train, y_train)\n",
    "pipe_KNN.fit(X_train_smote, y_train_smote)\n",
    "pipe_KNN.fit(X_train_nm, y_train_nm)\n",
    "\n",
    "print('KNN Performance')\n",
    "print('Original: {}'.format(pipe_KNN.score(X_test, y_test)))\n",
    "print('SMOTE: {}'.format(pipe_KNN.score(X_test_smote, y_test_smote)))\n",
    "print('NearMiss: {}'.format(pipe_KNN.score(X_test_nm, y_test_nm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switch gears to linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lin = data = pd.read_csv('Data/spotify_dataframe', index_col = 'Unnamed: 0')\n",
    "\n",
    "features = ['acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', \n",
    "           'tempo', 'valence', 'key', 'mode', 'count']\n",
    "\n",
    "X2 = data_lin[features]\n",
    "y2 = data_lin['popularity']\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train2, y_train2)\n",
    "y_hat = lr.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.1813054063079298\n"
     ]
    }
   ],
   "source": [
    "print('R^2: ', r2_score(y_test2, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>popularity</td>    <th>  R-squared:         </th>  <td>   0.179</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.179</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   544.9</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 Feb 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:07:11</td>     <th>  Log-Likelihood:    </th> <td>-1.4502e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 32539</td>      <th>  AIC:               </th>  <td>2.901e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 32525</td>      <th>  BIC:               </th>  <td>2.902e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>   53.2806</td> <td>    1.351</td> <td>   39.432</td> <td> 0.000</td> <td>   50.632</td> <td>   55.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acousticness</th>     <td>  -21.6318</td> <td>    0.578</td> <td>  -37.412</td> <td> 0.000</td> <td>  -22.765</td> <td>  -20.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>danceability</th>     <td>   -6.2634</td> <td>    0.930</td> <td>   -6.735</td> <td> 0.000</td> <td>   -8.086</td> <td>   -4.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>duration_ms</th>      <td>-7.293e-06</td> <td> 7.58e-07</td> <td>   -9.615</td> <td> 0.000</td> <td>-8.78e-06</td> <td>-5.81e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>energy</th>           <td>   -8.1010</td> <td>    1.044</td> <td>   -7.762</td> <td> 0.000</td> <td>  -10.147</td> <td>   -6.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>instrumentalness</th> <td>  -21.9779</td> <td>    0.394</td> <td>  -55.727</td> <td> 0.000</td> <td>  -22.751</td> <td>  -21.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>liveness</th>         <td>  -18.2588</td> <td>    0.811</td> <td>  -22.521</td> <td> 0.000</td> <td>  -19.848</td> <td>  -16.670</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loudness</th>         <td>   -0.2235</td> <td>    0.038</td> <td>   -5.840</td> <td> 0.000</td> <td>   -0.298</td> <td>   -0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>speechiness</th>      <td>  -10.4875</td> <td>    1.127</td> <td>   -9.307</td> <td> 0.000</td> <td>  -12.696</td> <td>   -8.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo</th>            <td>   -0.0309</td> <td>    0.005</td> <td>   -6.091</td> <td> 0.000</td> <td>   -0.041</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence</th>          <td>    3.1239</td> <td>    0.615</td> <td>    5.083</td> <td> 0.000</td> <td>    1.919</td> <td>    4.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key</th>              <td>   -0.0787</td> <td>    0.034</td> <td>   -2.344</td> <td> 0.019</td> <td>   -0.145</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mode</th>             <td>    0.7265</td> <td>    0.270</td> <td>    2.692</td> <td> 0.007</td> <td>    0.197</td> <td>    1.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count</th>            <td>    0.0003</td> <td>    0.002</td> <td>    0.146</td> <td> 0.884</td> <td>   -0.004</td> <td>    0.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1673.772</td> <th>  Durbin-Watson:     </th> <td>   1.872</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1099.053</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.331</td>  <th>  Prob(JB):          </th> <td>2.21e-239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 2.390</td>  <th>  Cond. No.          </th> <td>4.41e+06</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.41e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             popularity   R-squared:                       0.179\n",
       "Model:                            OLS   Adj. R-squared:                  0.179\n",
       "Method:                 Least Squares   F-statistic:                     544.9\n",
       "Date:                Sat, 06 Feb 2021   Prob (F-statistic):               0.00\n",
       "Time:                        18:07:11   Log-Likelihood:            -1.4502e+05\n",
       "No. Observations:               32539   AIC:                         2.901e+05\n",
       "Df Residuals:                   32525   BIC:                         2.902e+05\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept           53.2806      1.351     39.432      0.000      50.632      55.929\n",
       "acousticness       -21.6318      0.578    -37.412      0.000     -22.765     -20.498\n",
       "danceability        -6.2634      0.930     -6.735      0.000      -8.086      -4.441\n",
       "duration_ms      -7.293e-06   7.58e-07     -9.615      0.000   -8.78e-06   -5.81e-06\n",
       "energy              -8.1010      1.044     -7.762      0.000     -10.147      -6.055\n",
       "instrumentalness   -21.9779      0.394    -55.727      0.000     -22.751     -21.205\n",
       "liveness           -18.2588      0.811    -22.521      0.000     -19.848     -16.670\n",
       "loudness            -0.2235      0.038     -5.840      0.000      -0.298      -0.148\n",
       "speechiness        -10.4875      1.127     -9.307      0.000     -12.696      -8.279\n",
       "tempo               -0.0309      0.005     -6.091      0.000      -0.041      -0.021\n",
       "valence              3.1239      0.615      5.083      0.000       1.919       4.328\n",
       "key                 -0.0787      0.034     -2.344      0.019      -0.145      -0.013\n",
       "mode                 0.7265      0.270      2.692      0.007       0.197       1.256\n",
       "count                0.0003      0.002      0.146      0.884      -0.004       0.005\n",
       "==============================================================================\n",
       "Omnibus:                     1673.772   Durbin-Watson:                   1.872\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1099.053\n",
       "Skew:                           0.331   Prob(JB):                    2.21e-239\n",
       "Kurtosis:                       2.390   Cond. No.                     4.41e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.41e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'popularity ~ acousticness +danceability + duration_ms + energy + instrumentalness + liveness + loudness + speechiness + tempo + valence + key + mode + count'\n",
    "\n",
    "model = ols(formula= formula, data=data_lin).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin with vanilla models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with a KNN classifier\n",
    "\n",
    "clf_kn= KNeighborsClassifier()\n",
    "\n",
    "#fit\n",
    "clf_kn.fit(scaled_train, y_train)\n",
    "\n",
    "#predict\n",
    "y_hat = clf_kn.predict(scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.6165350679293381\n",
      "Recall Score: 0.6096566549759507\n",
      "Accuracy Score: 0.6544253226797787\n",
      "F1 Score: 0.6120948609905715\n"
     ]
    }
   ],
   "source": [
    "#check performance\n",
    "\n",
    "def print_metrics(test, preds):\n",
    "    print(\"Precision Score: {}\".format(precision_score(test, preds, average = 'macro')))\n",
    "    print(\"Recall Score: {}\".format(recall_score(test, preds, average = 'macro')))\n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(test, preds)))\n",
    "    print(\"F1 Score: {}\".format(f1_score(test, preds, average = 'macro')))\n",
    "    \n",
    "print_metrics(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider other k values\n",
    "\n",
    "def find_k(X_train, y_train, X_test, y_test, min_k=1, max_k=25):\n",
    "    best_k = 0\n",
    "    best_score = 0.0\n",
    "    for k in range(min_k, max_k+1, 2):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_hat = knn.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_hat, average = 'macro')\n",
    "        if f1 > best_score:\n",
    "            best_k = k\n",
    "            best_score = f1\n",
    "    print(\"Best Value for k: {}\".format(best_k))\n",
    "    print(\"F1-Score: {}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value for k: 13\n",
      "F1-Score: 0.6240938122700931\n"
     ]
    }
   ],
   "source": [
    "find_k(scaled_train, y_train, scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.6165350679293381\n",
      "Recall Score: 0.6096566549759507\n",
      "Accuracy Score: 0.6544253226797787\n",
      "F1 Score: 0.6120948609905715\n"
     ]
    }
   ],
   "source": [
    "#test performance for all metrics with the best k value\n",
    "\n",
    "clf_bestk = KNeighborsClassifier(n_neighbors = 13)\n",
    "\n",
    "clf_bestk.fit(scaled_train, y_train)\n",
    "\n",
    "y_hat_best = clf_bestk.predict(scaled_test)\n",
    "\n",
    "print_metrics(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Thoughts on KNN Outcome:\n",
    "Not a very good F1, with a slightly better accuracy score. Definitely not great and probably not the model I'll end up using. However, would like to go back and take a look at the cleaning to see what could make this better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to make some changes to the dataframe in hopes of improving the KNN model. First thought is to dummy the categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = ['key']\n",
    "df_knn = pd.get_dummies(X, columns = dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>...</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>key_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.598500</td>\n",
       "      <td>0.470100</td>\n",
       "      <td>267072.000000</td>\n",
       "      <td>0.376203</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.283050</td>\n",
       "      <td>-14.434300</td>\n",
       "      <td>0.209150</td>\n",
       "      <td>114.128800</td>\n",
       "      <td>0.358320</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.862538</td>\n",
       "      <td>0.441731</td>\n",
       "      <td>287280.000000</td>\n",
       "      <td>0.406808</td>\n",
       "      <td>0.081158</td>\n",
       "      <td>0.315215</td>\n",
       "      <td>-10.690000</td>\n",
       "      <td>0.176212</td>\n",
       "      <td>103.044154</td>\n",
       "      <td>0.268865</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.856571</td>\n",
       "      <td>0.348286</td>\n",
       "      <td>328920.000000</td>\n",
       "      <td>0.286571</td>\n",
       "      <td>0.024593</td>\n",
       "      <td>0.325786</td>\n",
       "      <td>-15.230714</td>\n",
       "      <td>0.118514</td>\n",
       "      <td>77.375857</td>\n",
       "      <td>0.354857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.884926</td>\n",
       "      <td>0.425074</td>\n",
       "      <td>262890.962963</td>\n",
       "      <td>0.245770</td>\n",
       "      <td>0.073587</td>\n",
       "      <td>0.275481</td>\n",
       "      <td>-15.639370</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>88.667630</td>\n",
       "      <td>0.372030</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.510714</td>\n",
       "      <td>0.467143</td>\n",
       "      <td>270436.142857</td>\n",
       "      <td>0.488286</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>-10.236714</td>\n",
       "      <td>0.098543</td>\n",
       "      <td>122.835857</td>\n",
       "      <td>0.482286</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability    duration_ms    energy  instrumentalness  \\\n",
       "0      0.598500      0.470100  267072.000000  0.376203          0.010261   \n",
       "1      0.862538      0.441731  287280.000000  0.406808          0.081158   \n",
       "2      0.856571      0.348286  328920.000000  0.286571          0.024593   \n",
       "3      0.884926      0.425074  262890.962963  0.245770          0.073587   \n",
       "4      0.510714      0.467143  270436.142857  0.488286          0.009400   \n",
       "\n",
       "   liveness   loudness  speechiness       tempo   valence  ...  key_2  key_3  \\\n",
       "0  0.283050 -14.434300     0.209150  114.128800  0.358320  ...      0      0   \n",
       "1  0.315215 -10.690000     0.176212  103.044154  0.268865  ...      0      0   \n",
       "2  0.325786 -15.230714     0.118514   77.375857  0.354857  ...      0      0   \n",
       "3  0.275481 -15.639370     0.123200   88.667630  0.372030  ...      0      0   \n",
       "4  0.195000 -10.236714     0.098543  122.835857  0.482286  ...      0      0   \n",
       "\n",
       "   key_4  key_5  key_6  key_7  key_8  key_9  key_10  key_11  \n",
       "0      0      1      0      0      0      0       0       0  \n",
       "1      0      1      0      0      0      0       0       0  \n",
       "2      0      0      0      0      0      0       0       0  \n",
       "3      0      0      0      0      0      0       0       0  \n",
       "4      0      1      0      0      0      0       0       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_knn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32539"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_knn = df_knn\n",
    "y_knn = df['popularity_labels']\n",
    "len(X_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(X_knn, y_knn, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_knn = scaler.fit_transform(X_train_knn)\n",
    "scaled_test_knn = scaler.fit_transform(X_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using new KNN X data with no adjustment to hyperparameters\n",
    "clf_knn = KNeighborsClassifier()\n",
    "\n",
    "clf_knn.fit(scaled_train_knn, y_train)\n",
    "y_hat_new_knn = clf_knn.predict(scaled_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.6057185290666891\n",
      "Recall Score: 0.597671990381845\n",
      "Accuracy Score: 0.6409035033804549\n",
      "F1 Score: 0.6001418884190932\n"
     ]
    }
   ],
   "source": [
    "print_metrics(y_test_knn, y_hat_new_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value for k: 1\n",
      "F1-Score: 0.607927114503413\n"
     ]
    }
   ],
   "source": [
    "#find the best K value and F1 score with the new X data\n",
    "find_k(scaled_train_knn, y_train_knn, scaled_test_knn, y_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final Thoughts | KNN\n",
    "KNN certainly doesn't seem very successful for this dataset. This F1 is lower than the vanilla model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving on to Trees!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will start with the original dataframe with no modification first \n",
    "Starting with a tree using entropy considering it's the most common method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 10)\n",
    "\n",
    "clf_tree.fit(X_train, y_train)\n",
    "y_hat_tree = clf_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6439766441303012\n",
      "F1: 0.6067395009548563\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Successful</th>\n",
       "      <th>Unsuccessful</th>\n",
       "      <th>Very Successful</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Successful</th>\n",
       "      <td>850</td>\n",
       "      <td>460</td>\n",
       "      <td>345</td>\n",
       "      <td>1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unsuccessful</th>\n",
       "      <td>449</td>\n",
       "      <td>2476</td>\n",
       "      <td>366</td>\n",
       "      <td>3291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Successful</th>\n",
       "      <td>324</td>\n",
       "      <td>373</td>\n",
       "      <td>865</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1623</td>\n",
       "      <td>3309</td>\n",
       "      <td>1576</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted        Successful  Unsuccessful  Very Successful   All\n",
       "True                                                            \n",
       "Successful              850           460              345  1655\n",
       "Unsuccessful            449          2476              366  3291\n",
       "Very Successful         324           373              865  1562\n",
       "All                    1623          3309             1576  6508"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(accuracy_score(y_test, y_hat_tree)))\n",
    "print('F1: {}'.format(f1_score(y_test, y_hat_tree, average = 'macro')))\n",
    "\n",
    "pd.crosstab(y_test, y_hat_tree, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's becoming obvious to me that the imbalanced nature of this dataset is affecting my model performance. In the next notebook, I'm going to solve for this problem and rerun my models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', random_state = 10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_hat_tree = clf.predict(X_test)\n",
    "y_hat_train = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6409547223929523\n",
      "Precision: 0.5989464108896949\n",
      "Recall: 0.5989123706150902\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3785</td>\n",
       "      <td>705</td>\n",
       "      <td>518</td>\n",
       "      <td>5008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>688</td>\n",
       "      <td>1205</td>\n",
       "      <td>533</td>\n",
       "      <td>2426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>531</td>\n",
       "      <td>530</td>\n",
       "      <td>1267</td>\n",
       "      <td>2328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>5004</td>\n",
       "      <td>2440</td>\n",
       "      <td>2318</td>\n",
       "      <td>9762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     1     2     3   All\n",
       "True                             \n",
       "1          3785   705   518  5008\n",
       "2           688  1205   533  2426\n",
       "3           531   530  1267  2328\n",
       "All        5004  2440  2318  9762"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(accuracy_score(y_test, y_hat_tree)))\n",
    "print('Precision: {}'.format(precision_score(y_test, y_hat_tree, average = 'macro')))\n",
    "print('Recall: {}'.format(recall_score(y_test, y_hat_tree, average = 'macro')))\n",
    "\n",
    "\n",
    "pd.crosstab(y_test, y_hat_tree, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.007840745055161635\n",
      "MSE: 0.8254803100413293\n"
     ]
    }
   ],
   "source": [
    "#double confirm results\n",
    "r2 = r2_score(y_test, y_hat_tree)\n",
    "rmse = mean_squared_error(y_test, y_hat_tree, squared=False)\n",
    "\n",
    "print('R2 Score: {}'.format(r2))\n",
    "print('MSE: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so with the same cleaning used for logsitic models, we get a very similar precison/ recall output. The Successful class is much cleaner compared to the logistic model - but the overall score still isn't promising. I've never seen a negative R2 before, so need to do research there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    9.5s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('classifier' , DecisionTreeClassifier())])\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier' : [DecisionTreeClassifier()],\n",
    "     'classifier__criterion' : ['gini', 'entropy'],\n",
    "    'classifier__class_weight' : ['balanced', 'None'],\n",
    "    'classifier__min_samples_split' : [1, 2, 4, 8]}]\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': DecisionTreeClassifier(class_weight='balanced', criterion='entropy'), 'classifier__class_weight': 'balanced', 'classifier__criterion': 'entropy', 'classifier__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(best_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6379840196681008\n",
      "Precision: 0.597080272607638\n",
      "Recall: 0.5964182675041684\n",
      "R2 Score: -0.052687537078061286\n",
      "MSE: 0.8436464885628417\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3762</td>\n",
       "      <td>689</td>\n",
       "      <td>557</td>\n",
       "      <td>5008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>692</td>\n",
       "      <td>1223</td>\n",
       "      <td>511</td>\n",
       "      <td>2426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581</td>\n",
       "      <td>504</td>\n",
       "      <td>1243</td>\n",
       "      <td>2328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>5035</td>\n",
       "      <td>2416</td>\n",
       "      <td>2311</td>\n",
       "      <td>9762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     1     2     3   All\n",
       "True                             \n",
       "1          3762   689   557  5008\n",
       "2           692  1223   511  2426\n",
       "3           581   504  1243  2328\n",
       "All        5035  2416  2311  9762"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', class_weight = 'balanced', min_samples_split = 2, random_state = 10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_hat_tree = clf.predict(X_test)\n",
    "y_hat_train = clf.predict(X_train)\n",
    "\n",
    "print('Accuracy: {}'.format(accuracy_score(y_test, y_hat_tree)))\n",
    "print('Precision: {}'.format(precision_score(y_test, y_hat_tree, average = 'macro')))\n",
    "print('Recall: {}'.format(recall_score(y_test, y_hat_tree, average = 'macro')))\n",
    "print('R2 Score: {}'.format(r2_score(y_test, y_hat_tree)))\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, y_hat_tree, squared=False)))\n",
    "\n",
    "\n",
    "pd.crosstab(y_test, y_hat_tree, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
